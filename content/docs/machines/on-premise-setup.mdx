---
title: On-Premise Setup
description: Set up custom self-hosted ComfyDeploy on-premise
---

This guide covers setting up custom self-hosted ComfyDeploy on-premise, allowing you to run ComfyUI workflows on your own infrastructure while integrating with the ComfyDeploy platform.

## Overview

ComfyDeploy supports three types of self-hosted machine configurations:

- **Classic machines**: Direct ComfyUI instances with endpoint configuration
- **RunPod serverless**: Self-hosted with serverless scaling capabilities  
- **Custom configurations**: Docker-based setups with custom nodes

Self-hosted machines give you full control over your infrastructure while maintaining integration with ComfyDeploy's workflow management and API.

## Prerequisites

### Hardware Requirements

- **GPU**: NVIDIA GPU with CUDA support (recommended: RTX 4090, A100, H100)
- **RAM**: Minimum 16GB, recommended 32GB+ for large models
- **Storage**: SSD with at least 100GB free space for models and outputs
- **Network**: Stable internet connection with public IP or port forwarding capability

### Software Requirements

- **Docker**: Latest version with GPU support (nvidia-docker2)
- **Python**: 3.11 or higher
- **Git**: For cloning repositories
- **CUDA**: Compatible version with your GPU drivers

### Network Configuration

Your self-hosted machine needs to be accessible from the internet:

- **Public IP** or **port forwarding** configured
- **Firewall rules** allowing inbound connections on your chosen port
- **SSL certificate** (recommended for production)

## Machine Creation

### 1. Create Self-Hosted Machine in ComfyDeploy

1. Navigate to the **Machines** section in your ComfyDeploy dashboard
2. Click **Create Machine** â†’ **Self Hosted Machine**
3. Configure your machine:

```json
{
  "name": "My On-Premise Machine",
  "type": "classic",
  "endpoint": "http://your-server-ip:8188",
  "auth_token": "your-secure-token"
}
```

**Machine Types:**
- `classic`: Standard ComfyUI instance with direct API access
- `runpod-serverless`: RunPod-based serverless deployment

### 2. Machine Configuration Options

**Classic Machine Schema:**
- **Name**: Descriptive name for your machine
- **Endpoint**: Your ComfyUI server URL (e.g., `http://192.168.1.100:8188`)
- **Type**: Set to `classic` for standard self-hosted setup
- **Auth Token**: Optional authentication token for security

## ComfyUI Installation

### 1. Clone ComfyUI Repository

```bash
git clone https://github.com/comfyanonymous/ComfyUI.git /comfyui
cd /comfyui
```

### 2. Install Dependencies

```bash
# Install Python dependencies
python -m pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu121
python -m pip install xformers
python -m pip install -r requirements.txt

# Install additional dependencies for ComfyDeploy integration
python -m pip install aioboto3
```

### 3. Directory Structure Setup

```bash
# Create required directories
mkdir -p /private_models/input
mkdir -p /comfyui/custom_nodes
mkdir -p /comfyui/models
```

## ComfyDeploy Custom Node Setup

### 1. Install ComfyDeploy Custom Node

```bash
cd /comfyui/custom_nodes
git clone https://github.com/BennyKok/comfyui-deploy --recursive
cd comfyui-deploy
git reset --hard 7b734c415aabd51b8bb8fad9fd719032b3b8a36fa
```

### 2. Install Node Dependencies

```bash
# Install requirements if available
if [ -f requirements.txt ]; then 
    python -m pip install -r requirements.txt
fi

# Run install script if available
if [ -f install.py ]; then 
    python install.py || echo 'install script failed'
fi
```

### 3. Install ComfyUI Manager (Optional)

```bash
cd /comfyui/custom_nodes
git clone https://github.com/ltdrdata/ComfyUI-Manager.git --recursive
cd ComfyUI-Manager
git reset --hard fd2d285af5ae257a4d1f3c1146981ce41ac5adf5
if [ -f requirements.txt ]; then python -m pip install -r requirements.txt; fi
if [ -f install.py ]; then python install.py || echo 'install script failed'; fi
```

## Custom Node Installation

### Using Docker Commands

For additional custom nodes, you can use Docker-style commands:

```dockerfile
# System packages
RUN apt-get update && apt-get install -y <package-name>

# Python packages
RUN pip install <package-name>

# Custom nodes from Git
WORKDIR /comfyui/custom_nodes
RUN git clone <git-url> --recursive
WORKDIR /comfyui/custom_nodes/<custom-node-name>
RUN git reset --hard <commit-hash>
RUN if [ -f requirements.txt ]; then python -m pip install -r requirements.txt; fi
RUN if [ -f install.py ]; then python install.py || echo "install script failed"; fi

# Models in custom node directories
RUN wget -P /comfyui/custom_nodes/<CustomNode-Directory> <model-url>
```

### Manual Installation

1. **Clone the custom node repository:**
```bash
cd /comfyui/custom_nodes
git clone https://github.com/author/custom-node-repo --recursive
```

2. **Install dependencies:**
```bash
cd custom-node-repo
pip install -r requirements.txt
python install.py
```

3. **Restart ComfyUI** to load the new nodes

## Endpoint Configuration

### 1. Start ComfyUI Server

```bash
cd /comfyui
python main.py \
  --dont-print-server \
  --enable-cors-header \
  --listen \
  --port 8188 \
  --input-directory /private_models/input \
  --preview-method auto
```

### 2. Configure Authentication (Optional)

For secure deployments, set up authentication:

```bash
# Set auth token environment variable
export COMFYUI_AUTH_TOKEN="your-secure-token"

# Start with authentication
python main.py \
  --dont-print-server \
  --enable-cors-header \
  --listen \
  --port 8188 \
  --input-directory /private_models/input \
  --preview-method auto \
  --auth-token $COMFYUI_AUTH_TOKEN
```

### 3. Test Endpoint Connectivity

```bash
# Test basic connectivity
curl http://your-server-ip:8188/system_stats

# Test ComfyDeploy integration
curl -X POST http://your-server-ip:8188/comfyui-deploy/run \
  -H "Content-Type: application/json" \
  -H "Authorization: Basic $(echo -n 'your-auth-token' | base64)" \
  -d '{"cd_token": "test"}'
```

## Docker Deployment (Advanced)

### 1. Create Dockerfile

```dockerfile
FROM nvidia/cuda:12.1-devel-ubuntu22.04

# Install system dependencies
RUN apt-get update && apt-get install -y \
    python3 python3-pip git wget curl \
    libgl1-mesa-glx libglib2.0-0 \
    && rm -rf /var/lib/apt/lists/*

# Install Python dependencies
RUN python3 -m pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu121
RUN python3 -m pip install xformers aioboto3

# Clone ComfyUI
RUN git clone https://github.com/comfyanonymous/ComfyUI.git /comfyui
WORKDIR /comfyui
RUN python3 -m pip install -r requirements.txt

# Install ComfyDeploy custom node
WORKDIR /comfyui/custom_nodes
RUN git clone https://github.com/BennyKok/comfyui-deploy --recursive
WORKDIR /comfyui/custom_nodes/comfyui-deploy
RUN git reset --hard 7b734c415aabd51b8bb8fad9fd719032b3b8a36fa
RUN if [ -f requirements.txt ]; then python3 -m pip install -r requirements.txt; fi
RUN if [ -f install.py ]; then python3 install.py || echo 'install script failed'; fi

# Create required directories
RUN mkdir -p /private_models/input

WORKDIR /comfyui
EXPOSE 8188

CMD ["python3", "main.py", "--dont-print-server", "--enable-cors-header", "--listen", "--port", "8188", "--input-directory", "/private_models/input", "--preview-method", "auto"]
```

### 2. Build and Run Container

```bash
# Build image
docker build -t comfyui-deploy-onpremise .

# Run container
docker run -d \
  --name comfyui-deploy \
  --gpus all \
  -p 8188:8188 \
  -v /path/to/models:/comfyui/models \
  -v /path/to/outputs:/comfyui/output \
  comfyui-deploy-onpremise
```

## Integration with ComfyDeploy

### 1. Update Machine Configuration

After setting up your on-premise instance:

1. Go to your machine settings in ComfyDeploy
2. Update the endpoint URL to match your server
3. Set the authentication token if configured
4. Test the connection

### 2. API Integration

Your self-hosted machine will receive workflow execution requests at:

```
POST http://your-server-ip:8188/comfyui-deploy/run
```

**Request Format:**
```json
{
  "workflow": { /* ComfyUI workflow JSON */ },
  "inputs": { /* Input parameters */ },
  "cd_token": "your-comfydeploy-token"
}
```

### 3. Authentication Handling

For classic machines, ComfyDeploy uses Basic Authentication:

```bash
# Auth header format
Authorization: Basic <base64-encoded-token>
authorizationheader: <raw-token>
```

## Troubleshooting

### Common Issues

**1. Connection Refused**
- Check if ComfyUI is running on the correct port
- Verify firewall settings allow inbound connections
- Ensure the endpoint URL is accessible from the internet

**2. Authentication Errors**
- Verify auth token matches between ComfyDeploy and your server
- Check that authentication headers are properly configured
- Test authentication with curl commands

**3. Custom Node Loading Issues**
- Restart ComfyUI after installing new custom nodes
- Check custom node dependencies are installed
- Verify custom node compatibility with your ComfyUI version

**4. GPU Not Detected**
- Install nvidia-docker2 for Docker deployments
- Verify CUDA installation and GPU drivers
- Check that `--gpus all` flag is used in Docker run command

### Performance Optimization

**1. Model Loading**
- Pre-download frequently used models to reduce startup time
- Use model caching to avoid repeated downloads
- Consider using faster storage (NVMe SSD) for model storage

**2. Memory Management**
- Monitor GPU memory usage during workflow execution
- Adjust batch sizes based on available GPU memory
- Use model offloading for large models if needed

**3. Network Optimization**
- Use CDN or local storage for large input files
- Implement proper caching strategies
- Consider using compression for API responses

### Monitoring and Logging

**1. System Monitoring**
```bash
# Monitor GPU usage
nvidia-smi -l 1

# Monitor system resources
htop

# Check ComfyUI logs
tail -f /comfyui/comfyui.log
```

**2. API Monitoring**
- Monitor endpoint response times
- Track workflow execution success rates
- Set up alerts for system failures

## Security Considerations

### 1. Network Security
- Use HTTPS/TLS for production deployments
- Implement proper firewall rules
- Consider VPN access for sensitive deployments

### 2. Authentication
- Use strong, unique authentication tokens
- Rotate tokens regularly
- Implement rate limiting to prevent abuse

### 3. Data Protection
- Secure model and output storage
- Implement proper backup strategies
- Consider data encryption for sensitive workflows

## Next Steps

After setting up your on-premise ComfyDeploy instance:

1. **Test workflow execution** through the ComfyDeploy interface
2. **Monitor performance** and optimize as needed
3. **Set up monitoring and alerting** for production use
4. **Implement backup and disaster recovery** procedures
5. **Scale horizontally** by adding more machines as needed

For additional support and advanced configurations, refer to the [ComfyDeploy documentation](https://docs.comfydeploy.com) or contact the support team.
